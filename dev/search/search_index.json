{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Geist documentation","text":"<p>Geist is a new templating language for declarative data manipulation, query, and report generation. Building on the Jinja2 template engine, Geist is designed to support diverse data backends and query engines via predefined tags and filters, and may be extended with custom tags. A single Geist template may include multiple queries expressed in different languages, e.g. SQL and SPARQL, to leverage the strengths of each for clarity and ease of maintenance. Because Geist both can generate reports in diverse formats and perform inserts and updates on new or existing databases during template expansion, Geist templates may orchestrate data extraction, transformation, and load operations spanning multiple tools and data storage systems. The Geist Python package can be installed easily and accessed via the command line. If your dataset is stored in DuckDB and SPARQL queries are more suitable for your problem, then Geist might be for you! Check out our Poster for SciPy 2024!</p> <p>At the moment, Geist supports DuckDB and RDFLib. More types of data backends will be available in the near future.</p>"},{"location":"#features","title":"Features","text":"<p>Both CLI and Python API provide the following features:</p> <ul> <li>report feature: expand a report using dataset(s)</li> <li>create feature: create a new dataset</li> <li>destroy feature: delete a dataset</li> <li>export feature: export a graph</li> <li>graph feature: visualize a dataset</li> <li>load feature: import data into a dataset</li> <li>query feature: perform a query on a dataset</li> </ul>"},{"location":"#demo-for-scipy-2024","title":"Demo for SciPy 2024","text":"<p>A Geist report that employs two different query languages. We demonstrate how Geist can be used to extract triples from a relational database, store them as a RDF dataset, and perform SPARQL queries on it. Instead of purely in-memory operations, Geist can be used to migrate data. With the hamming numbers dataset stored in DuckDB as an input, we generate a report to describe the original dataset and the subgraph extracted via SQL and SPARQL queries using a single Geist script.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v021","title":"v0.2.1","text":"<ul> <li>Add the Geist Poster for SciPy 2024</li> <li>Update the documentation: add descriptions for the demo of SciPy 2024</li> </ul>"},{"location":"changelog/#v020","title":"v0.2.0","text":"<ul> <li>SQL queries are supported by GEIST based on duckdb</li> <li>Update ContainerTag: return objects of any type, not just strings</li> </ul>"},{"location":"changelog/#v010","title":"v0.1.0","text":"<ul> <li>Add documentation</li> <li>Add the component tag to extract connected components of a given graph</li> <li>Add the process_str_for_html filter</li> <li>Make the map tag more flexible: make it possible to map selected columns</li> <li>Fix the quotes bug: keep the cell's original format</li> </ul>"},{"location":"changelog/#v001","title":"v0.0.1","text":"<ul> <li>The first version of GEIST with create, load, query, destroy, graph, graph2, map, use, html, img, and table tags</li> <li>SPARQL queries are supported by GEIST based on RDFLib</li> </ul>"},{"location":"setup/","title":"Setup","text":"<p>Before installing Geist, please make sure Graphviz is installed. </p> Example: GitHub Codespaces <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y graphviz graphviz-dev\n</code></pre> Example: Google Colab (Jupyter Notebook) <pre><code>apt install libgraphviz-dev\n</code></pre> <p>Install Geist: <pre><code>pip install geist-p\n</code></pre></p> <p>To check Geist is working, run <code>geist</code> in the command line. You should get the following output: <pre><code>Usage: geist [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  create   Create a new dataset\n  destroy  Delete a dataset\n  export   Export a dataset\n  graph    Visualize a dataset\n  load     Import data into a dataset\n  query    Perform a query on a dataset\n  report   Expand a report using dataset(s)\n</code></pre></p>"},{"location":"cli/create/","title":"Command create","text":"<p>The create command has two subcommands, both of which create a new dataset on disk. The dataset name <code>:memory:</code> is a reserved value for datasets that exist only in memory and is not allowed in the CLI.</p> <pre><code>Usage: geist create [OPTIONS] COMMAND [ARGS]...\n\nCreate a new dataset\n\nOptions:\n--help  Show this message and exit.\n\nCommands:\nduckdb  Create a new SQL dataset using DuckDB\nrdflib  Create a new RDF dataset using RDFLib\n</code></pre> geist create duckdb [OPTIONS] <pre><code>Usage: geist create duckdb [OPTIONS]\n\nCreate a new SQL dataset using DuckDB\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as a Pandas\n                                DataFrame  [required]\n-iformat, --inputformat [csv|json]\n                                Format of the file to be loaded as a Pandas\n                                DataFrame (default csv)\n-t, --table TEXT                Name of the table to be created (default\n                                \"df\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> SQL dataset from stdin <pre><code>geist create duckdb --dataset test --inputformat csv --table df &lt;&lt; __END_INPUT__\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>geist create duckdb --dataset test --inputfile test.csv --inputformat csv --table df\n</code></pre></p> geist create rdflib [OPTIONS] <pre><code>Usage: geist create rdflib [OPTIONS]\n\nCreate a new RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as triples\n                                [required]\n-iformat, --inputformat [xml|n3|turtle|nt|pretty-xml|trix|trig|nquads|json-ld|hext|csv]\n                                Format of the file to be loaded as triples\n                                (default json-ld)\n--colnames TEXT                 Column names of triples with the format of\n                                [[subject1, predicate1, object1], [subject2,\n                                predicate2, object2], ...] when the input\n                                format is csv\n--infer [none|rdfs|owl|rdfs_owl]\n                                Inference to perform on update [none, rdfs,\n                                owl, rdfs_owl] (default \"none\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> RDF dataset from stdin <pre><code>geist create rdflib --dataset test --inputformat nt --infer none &lt;&lt; __END_INPUT__\n\n&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.nt</code> file:</p> <p><pre><code>&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n</code></pre> Code: <pre><code>geist create rdflib --dataset test --inputfile test.nt --inputformat nt --infer none\n</code></pre></p>"},{"location":"cli/destroy/","title":"Command destroy","text":"<p>destroy command can delete a dataset. The <code>.duckdb</code> or the <code>.pkl</code> file of the corresponding dataset will be discarded.</p> <p>There are two subcommands for destroy: <pre><code>Usage: geist destroy [OPTIONS] COMMAND [ARGS]...\n\n  Delete a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Delete a SQL dataset\n  rdflib  Delete an RDF dataset\n</code></pre></p> geist destroy duckdb [OPTIONS] <pre><code>Usage: geist destroy duckdb [OPTIONS]\n\nDelete a SQL dataset\n\nOptions:\n-d, --dataset TEXT  Name of SQL dataset to be removed (default \"kb\")\n-q, --quiet         Suppress error messages if the provided dataset does not\n                    exist\n--help              Show this message and exit.\n</code></pre> Example: delete the <code>test</code> dataset <pre><code>geist destroy duckdb --dataset test\n</code></pre> <p>The <code>.geistdata/duckdb/test.duckdb</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can add <code>--quiet</code>:</p> <pre><code>geist destroy duckdb --dataset test --quiet\n</code></pre> geist destroy rdflib [OPTIONS] <pre><code>Usage: geist destroy rdflib [OPTIONS]\n\nDelete an RDF dataset\n\nOptions:\n-d, --dataset TEXT  Name of RDF dataset to be removed (default \"kb\")\n-q, --quiet         Suppress error messages if the provided dataset does not\n                    exist\n--help              Show this message and exit.\n</code></pre> Example: delete the <code>test</code> dataset <pre><code>geist destroy rdflib --dataset test\n</code></pre> <p>The <code>.geistdata/rdflib/test.pkl</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can add <code>--quiet</code>:</p> <pre><code>geist destroy rdflib --dataset test --quiet\n</code></pre>"},{"location":"cli/export/","title":"Command export","text":"<p>export command can export a dataset.</p> <p>There are two subcommands for export: <pre><code>Usage: geist export [OPTIONS] COMMAND [ARGS]...\n\n  Export a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Export a SQL dataset\n  rdflib  Export an RDF dataset\n</code></pre></p> geist export duckdb [OPTIONS] <pre><code>Usage: geist export duckdb [OPTIONS]\n\nExport a SQL dataset\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to be exported (default\n                                \"kb\")\n-oroot, --outputroot TEXT       Path of the directory to store the exported\n                                table (default: current directory). If the\n                                given path (i.e., --outputfile) is None or a\n                                relative path, it will be ignored.\n-ofile, --outputfile TEXT       Path of the file to store the exported table\n                                (default: None)\n-oformat, --outputformat [csv|json]\n                                Format of the exported table (default csv)\n-t, --table TEXT                Name of the table to be exported (default\n                                \"df\")\n--help                          Show this message and exit.\n</code></pre> Example: export the <code>df</code> table in <code>test</code> dataset <p>By default, the exported table will be printed in terminal: <pre><code>geist export duckdb --dataset test --table df\n</code></pre></p> geist export rdflib [OPTIONS] <pre><code>Usage: geist export rdflib [OPTIONS]\n\nExport an RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to be exported (default\n                                \"kb\")\n-oroot, --outputroot TEXT       Path of the directory to store these\n                                exported triples (default: current\n                                directory). If the given path (i.e.,\n                                --outputfile) is None or a relative path, it\n                                will be ignored.\n-ofile, --outputfile TEXT       Path of the file to store these exported\n                                triples (default: None)\n-oformat, --outputformat [json-ld|n3|nquads|nt|hext|pretty-xml|trig|trix|turtle|longturtle|xml]\n                                Format of the exported triples (default nt)\n--help                          Show this message and exit.\n</code></pre> Example: export the <code>test</code> dataset <p>By default, the exported triples will be printed in terminal: <pre><code>geist export rdflib --dataset test\n</code></pre></p>"},{"location":"cli/graph/","title":"Command graph","text":"<p>graph command can visualize a dataset. Only <code>rdflib</code> is supported for now.</p> <pre><code>Usage: geist graph [OPTIONS] COMMAND [ARGS]...\n\n  Visualize a dataset\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> geist graph rdflib [OPTIONS] <pre><code>Usage: geist graph rdflib [OPTIONS]\n\nVisualize an RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to be visualized\n                                (default \"kb\")\n-r, --rankdir [TB|BT|LR|RL]     Direction of the graph (default TB): TB or\n                                BT or LR or RL\n-m, --mappings TEXT             File of the mappings to shorten text (str):\n                                path of a JSON file, where the key is the\n                                original text and the value is the shorter\n                                text.\n-on, --on TEXT                  Column(s) to be mapped.\n-sc, --samecolor                Use the same color for same edges.\n-oroot, --outputroot TEXT       Path of the directory to store the graph\n                                (default: current directory). If the given\n                                path (i.e., --outputfile) is a relative\n                                path, it will be ignored.\n-ofile, --outputfile TEXT       Path of the file without extension to store\n                                the graph (default: res)\n-oformat, --outputformat [none|svg|png|gv]\n                                Format of the graph (default: none): none or\n                                svg or png or gv\n--help                          Show this message and exit.\n</code></pre> Example: visualize the <code>test</code> dataset <pre><code>geist graph rdflib --dataset test --outputformat svg \n</code></pre>"},{"location":"cli/load/","title":"Command load","text":"<p>load command can import data into an existing dataset.</p> <p>There are two subcommands for load: <pre><code>Usage: geist load [OPTIONS] COMMAND [ARGS]...\n\nImport data into a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Import data into a SQL dataset\n  rdflib  Import data into a RDF dataset\n</code></pre></p> geist load duckdb [OPTIONS] <pre><code>Usage: geist load duckdb [OPTIONS]\n\nImport data into a SQL dataset\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to load a file (default\n                                \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as a table\n                                [required]\n-iformat, --inputformat [csv|json]\n                                Format of the file to be loaded as a table\n                                (default csv)\n-t, --table TEXT                Name of the table to be created  [required]\n--help                          Show this message and exit.\n</code></pre> Example: load a file into the <code>test</code> dataset <pre><code>geist load duckdb --dataset test --inputfile test_add.csv --inputformat csv --table df\n</code></pre> geist load rdflib [OPTIONS] <p>Here are options of the load command: <pre><code>Usage: geist load rdflib [OPTIONS]\n\nImport data into a RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to load a file (default\n                                \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as triples\n                                [required]\n-iformat, --inputformat [xml|n3|turtle|nt|pretty-xml|trix|trig|nquads|json-ld|hext|csv]\n                                Format of the file to be loaded as triples\n                                (default json-ld)\n--colnames TEXT                 Column names of triples with the format of\n                                [[subject1, predicate1, object1], [subject2,\n                                predicate2, object2], ...] when the input\n                                format is csv\n--help                          Show this message and exit.\n</code></pre></p> Example: load a file into the <code>test</code> dataset <pre><code>geist load rdflib --dataset test --inputfile test_add.jsonld\n</code></pre>"},{"location":"cli/query/","title":"Command query","text":"<p>query command can perform a query on a dataset.</p> <p>There are two subcommands for query: <pre><code>Usage: geist query [OPTIONS] COMMAND [ARGS]...\n\n  Perform a query on a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Perform a SQL query on a dataset\n  rdflib  Perform a SPARQL query on a dataset\n</code></pre></p> geist query duckdb [OPTIONS] <pre><code>Usage: geist query duckdb [OPTIONS]\n\nPerform a SQL query on a dataset\n\nOptions:\n-d, --dataset TEXT            Name of RDF dataset to be queried (default\n                                \"kb\")\n-ifile, --inputfile FILENAME  Specify either the path of the file containing\n                                the SQL query to execute or provide the SQL\n                                query itself via stdin  [required]\n-oroot, --outputroot TEXT     Path of the directory to store the query\n                                results (default: current directory). If the\n                                given path (i.e., --outputfile) is None or a\n                                relative path, it will be ignored.\n-ofile, --outputfile TEXT     Path of the file to store the query results\n                                (default: None)\n--help                        Show this message and exit.\n</code></pre> Example 1: all rows of the <code>df</code> table in <code>test</code> dataset from stdin <pre><code>geist query duckdb --dataset test &lt;&lt; __END_QUERY__\n\nSELECT * FROM df\n\n__END_QUERY__\n</code></pre> Example 2: all rows of the <code>test</code> dataset from a query file <pre><code>geist query duckdb --dataset test --inputfile query_file\n</code></pre> <p>Here is the query_file's content: <pre><code>SELECT * FROM df\n</code></pre></p> geist query rdflib [OPTIONS] <pre><code>Usage: geist query rdflib [OPTIONS]\n\nPerform a SPARQL query on a dataset\n\nOptions:\n-d, --dataset TEXT            Name of RDF dataset to be queried (default\n                                \"kb\")\n-ifile, --inputfile FILENAME  Specify either the path of the file containing\n                                the SPARQL query to execute or provide the\n                                SPARQL query itself via stdin  [required]\n-oroot, --outputroot TEXT     Path of the directory to store the query\n                                results (default: current directory). If the\n                                given path (i.e., --outputfile) is None or a\n                                relative path, it will be ignored.\n-ofile, --outputfile TEXT     Path of the file to store the query results\n                                (default: None)\n--help                        Show this message and exit.\n</code></pre> Example 1: all triples of the <code>test</code> dataset from stdin <pre><code>geist query rdflib --dataset test &lt;&lt; __END_QUERY__\n\nSELECT ?s ?p ?o\nWHERE {\n    ?s ?p ?o\n}\nORDER BY ?s ?p ?o\n\n__END_QUERY__\n</code></pre> Example 2: all triples of the <code>test</code> dataset from a query file <pre><code>geist query rdflib --dataset test --inputfile query_file\n</code></pre> <p>Here is the query_file's content: <pre><code>SELECT ?s ?p ?o\nWHERE {\n    ?s ?p ?o\n}\nORDER BY ?s ?p ?o\n</code></pre></p>"},{"location":"cli/report/","title":"Command report","text":"<p>report command can expand a report (Geist template) using dataset(s).</p> <p>Here are options of the report command: <pre><code>Usage: geist report [OPTIONS]\n\nExpand a report using dataset(s)\n\nOptions:\n-ifile, --inputfile FILENAME   Path of the file containing the report\n                                template to expand  [required]\n-oroot, --outputroot TEXT      Path of the directory to store the expanded\n                                report (default: current directory)\n-so, --suppressoutput BOOLEAN  Suppress output or not (default: False)\n--help                         Show this message and exit.\n</code></pre></p> Example 1: expand a report from stdin <pre><code>geist report &lt;&lt; END_TEMPLATE\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\nEND_TEMPLATE\n</code></pre> Example 2: expand a report from a file <pre><code>geist report --inputfile report.geist\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p>"},{"location":"features/create/","title":"Create","text":"<p>create feature can create a new dataset on disk or in memory. For the disk option, a <code>.duckdb</code> or a <code>.pkl</code> file will be created under the <code>.geistdata/duckdb</code> or the <code>.geistdata/rdflib</code> folder with the same name of this dataset. For the memory option, a <code>DuckDBPyConnection</code> object or a <code>GeistGraph</code> object (a dictionary with \"rdf_graph\" and \"infer\" keys) will be returned.</p> <p>You can write a Geist template with the create tag. You can also use CLI or Python API step by step as follows:</p> CLI: create commandPython API: create() functionPython API: create method of the Connection Class <p>The create command has two subcommands, both of which create a new dataset on disk. The dataset name <code>:memory:</code> is a reserved value for datasets that exist only in memory and is not allowed in the CLI.</p> <pre><code>Usage: geist create [OPTIONS] COMMAND [ARGS]...\n\nCreate a new dataset\n\nOptions:\n--help  Show this message and exit.\n\nCommands:\nduckdb  Create a new SQL dataset using DuckDB\nrdflib  Create a new RDF dataset using RDFLib\n</code></pre> geist create duckdb [OPTIONS] <pre><code>Usage: geist create duckdb [OPTIONS]\n\nCreate a new SQL dataset using DuckDB\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as a Pandas\n                                DataFrame  [required]\n-iformat, --inputformat [csv|json]\n                                Format of the file to be loaded as a Pandas\n                                DataFrame (default csv)\n-t, --table TEXT                Name of the table to be created (default\n                                \"df\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> SQL dataset from stdin <pre><code>geist create duckdb --dataset test --inputformat csv --table df &lt;&lt; __END_INPUT__\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>geist create duckdb --dataset test --inputfile test.csv --inputformat csv --table df\n</code></pre></p> geist create rdflib [OPTIONS] <pre><code>Usage: geist create rdflib [OPTIONS]\n\nCreate a new RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as triples\n                                [required]\n-iformat, --inputformat [xml|n3|turtle|nt|pretty-xml|trix|trig|nquads|json-ld|hext|csv]\n                                Format of the file to be loaded as triples\n                                (default json-ld)\n--colnames TEXT                 Column names of triples with the format of\n                                [[subject1, predicate1, object1], [subject2,\n                                predicate2, object2], ...] when the input\n                                format is csv\n--infer [none|rdfs|owl|rdfs_owl]\n                                Inference to perform on update [none, rdfs,\n                                owl, rdfs_owl] (default \"none\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> RDF dataset from stdin <pre><code>geist create rdflib --dataset test --inputformat nt --infer none &lt;&lt; __END_INPUT__\n\n&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.nt</code> file:</p> <p><pre><code>&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n</code></pre> Code: <pre><code>geist create rdflib --dataset test --inputfile test.nt --inputformat nt --infer none\n</code></pre></p> <p>create function can create a new dataset on disk or in memory.</p> <p>Parameters description for create():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset to be created. Note that <code>:memory:</code> is a reserved value for datasets that exist only in memory [required] inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset on disk from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset on disk from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> <p>create method of the Connection class creates a new dataset on disk or in memory. It is very similar to the <code>create()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for create method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p>"},{"location":"features/destroy/","title":"Destroy","text":"<p>destroy feature can delete a dataset stored on disk or close a connection in memory.</p> <p>You can write a Geist template with the destroy tag. You can also use CLI or Python API step by step as follows:</p> CLI: destroy commandPython API: destroy() functionPython API: destroy method of the Connection ClassPython API: close method of the Connection Class <p>destroy command can delete a dataset. The <code>.duckdb</code> or the <code>.pkl</code> file of the corresponding dataset will be discarded.</p> <p>There are two subcommands for destroy: <pre><code>Usage: geist destroy [OPTIONS] COMMAND [ARGS]...\n\n  Delete a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Delete a SQL dataset\n  rdflib  Delete an RDF dataset\n</code></pre></p> geist destroy duckdb [OPTIONS] <pre><code>Usage: geist destroy duckdb [OPTIONS]\n\nDelete a SQL dataset\n\nOptions:\n-d, --dataset TEXT  Name of SQL dataset to be removed (default \"kb\")\n-q, --quiet         Suppress error messages if the provided dataset does not\n                    exist\n--help              Show this message and exit.\n</code></pre> Example: delete the <code>test</code> dataset <pre><code>geist destroy duckdb --dataset test\n</code></pre> <p>The <code>.geistdata/duckdb/test.duckdb</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can add <code>--quiet</code>:</p> <pre><code>geist destroy duckdb --dataset test --quiet\n</code></pre> geist destroy rdflib [OPTIONS] <pre><code>Usage: geist destroy rdflib [OPTIONS]\n\nDelete an RDF dataset\n\nOptions:\n-d, --dataset TEXT  Name of RDF dataset to be removed (default \"kb\")\n-q, --quiet         Suppress error messages if the provided dataset does not\n                    exist\n--help              Show this message and exit.\n</code></pre> Example: delete the <code>test</code> dataset <pre><code>geist destroy rdflib --dataset test\n</code></pre> <p>The <code>.geistdata/rdflib/test.pkl</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can add <code>--quiet</code>:</p> <pre><code>geist destroy rdflib --dataset test --quiet\n</code></pre> <p>destroy function can delete a dataset.</p> <p>Parameters description for destroy():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset to be removed. [required] quiet bool True to suppress error messages if the provided dataset does not exist False Example: delete the <code>test</code> dataset <pre><code>import geist\ngeist.destroy(datastore='rdflib', dataset='test')\n</code></pre> <p>The <code>.geistdata/rdflib/test.pkl</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can set <code>quiet=True</code>:</p> <pre><code>import geist\ngeist.destroy(datastore='rdflib', dataset='test', quiet=True)\n</code></pre> <p>destroy method of the Connection* class is to delete the dataset and close the dataset connection.</p> Example: delete the dataset and close the connection <p>Suppose <code>connection</code> is the instance of the Connection class for a DuckDB dataset named <code>test</code> stored on disk. The following code will delete the <code>.geistdata/duckdb/test.duckdb</code> file.</p> <pre><code># Delete the dataset and close the connection\nconnection.destroy()\n</code></pre> <p>close method of the Connection* class is to close the dataset connection, i.e., reset all attributes to None. No parameters are required.</p> Example: close the connection <p>Suppose <code>connection</code> is the instance of the Connection class.</p> <pre><code># Close the connection\nconnection.close()\n</code></pre>"},{"location":"features/export/","title":"Export","text":"<p>export feature can export a dataset stored on disk or in memory.</p> <p>You can use CLI or Python API as follows:</p> CLI: export commandPython API: export() functionPython API: export method of the Connection Class <p>export command can export a dataset.</p> <p>There are two subcommands for export: <pre><code>Usage: geist export [OPTIONS] COMMAND [ARGS]...\n\n  Export a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Export a SQL dataset\n  rdflib  Export an RDF dataset\n</code></pre></p> geist export duckdb [OPTIONS] <pre><code>Usage: geist export duckdb [OPTIONS]\n\nExport a SQL dataset\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to be exported (default\n                                \"kb\")\n-oroot, --outputroot TEXT       Path of the directory to store the exported\n                                table (default: current directory). If the\n                                given path (i.e., --outputfile) is None or a\n                                relative path, it will be ignored.\n-ofile, --outputfile TEXT       Path of the file to store the exported table\n                                (default: None)\n-oformat, --outputformat [csv|json]\n                                Format of the exported table (default csv)\n-t, --table TEXT                Name of the table to be exported (default\n                                \"df\")\n--help                          Show this message and exit.\n</code></pre> Example: export the <code>df</code> table in <code>test</code> dataset <p>By default, the exported table will be printed in terminal: <pre><code>geist export duckdb --dataset test --table df\n</code></pre></p> geist export rdflib [OPTIONS] <pre><code>Usage: geist export rdflib [OPTIONS]\n\nExport an RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to be exported (default\n                                \"kb\")\n-oroot, --outputroot TEXT       Path of the directory to store these\n                                exported triples (default: current\n                                directory). If the given path (i.e.,\n                                --outputfile) is None or a relative path, it\n                                will be ignored.\n-ofile, --outputfile TEXT       Path of the file to store these exported\n                                triples (default: None)\n-oformat, --outputformat [json-ld|n3|nquads|nt|hext|pretty-xml|trig|trix|turtle|longturtle|xml]\n                                Format of the exported triples (default nt)\n--help                          Show this message and exit.\n</code></pre> Example: export the <code>test</code> dataset <p>By default, the exported triples will be printed in terminal: <pre><code>geist export rdflib --dataset test\n</code></pre></p> <p>export function can export a dataset.</p> <p>Parameters description for export():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default outputroot string Path of the directory to store the exported table './' outputfile string Path of the file to store the exported table None outputformat string Format of the exported table, i.e., 'csv' or 'json' 'csv' table string Name of the table to be exported 'df' Key Type Description Default outputroot string Path of the directory to store these exported triples './' outputfile string Path of the file to store these exported triples None outputformat string Format of the exported triples, i.e., 'json-ld', 'n3', 'nquads', 'nt', 'hext', 'pretty-xml', 'trig', 'trix', 'turtle', 'longturtle', or 'xml'. 'nt' Example 1: export all rows of the <code>df</code> table in <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>data</code> and the DuckPyConnection<code>object</code>conn`.</p> <pre><code>import geist\n\n# Export the df table of the test dataset\n(data, conn) = geist.export(datastore='duckdb', dataset='test', hasoutput=False, config={'table': 'df'})\n</code></pre> Example 2: export all rows of the <code>df</code> table in <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>data</code> and the same DuckPyConnection<code>object</code>conn`.</p> <pre><code>import geist\n\n# Export the df table of the test dataset\n(data, conn) = geist.export(datastore='duckdb', dataset=conn, hasoutput=False, config={'table': 'df'})\n</code></pre> <p>export method of the Connection class exports a dataset. It is very similar to the <code>export()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for export method of the Connection class:</p> Name Type Description Default hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default outputroot string Path of the directory to store the exported table './' outputfile string Path of the file to store the exported table None outputformat string Format of the exported table, i.e., 'csv' or 'json' 'csv' table string Name of the table to be exported 'df' Key Type Description Default outputroot string Path of the directory to store these exported triples './' outputfile string Path of the file to store these exported triples None outputformat string Format of the exported triples, i.e., 'json-ld', 'n3', 'nquads', 'nt', 'hext', 'pretty-xml', 'trig', 'trix', 'turtle', 'longturtle', or 'xml'. 'nt' Example 1: export all rows of the <code>df</code> table in <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Export the df table of the test dataset\ndata = connection.export(hasoutput=False, config={'table': 'df'})\n</code></pre> Example 2: export all rows of the <code>df</code> table in <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Export the df table of the test dataset\ndata = connection.export( hasoutput=False, config={'table': 'df'})\n</code></pre>"},{"location":"features/graph/","title":"Graph","text":"<p>graph feature can visualize a dataset stored on disk or in memory.</p> <p>You can write a Geist template with the graph tag. You can also use CLI or Python API step by step as follows:</p> CLI: graph commandPython API: graph() functionPython API: graph method of the Connection Class <p>graph command can visualize a dataset. Only <code>rdflib</code> is supported for now.</p> <pre><code>Usage: geist graph [OPTIONS] COMMAND [ARGS]...\n\n  Visualize a dataset\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> geist graph rdflib [OPTIONS] <pre><code>Usage: geist graph rdflib [OPTIONS]\n\nVisualize an RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to be visualized\n                                (default \"kb\")\n-r, --rankdir [TB|BT|LR|RL]     Direction of the graph (default TB): TB or\n                                BT or LR or RL\n-m, --mappings TEXT             File of the mappings to shorten text (str):\n                                path of a JSON file, where the key is the\n                                original text and the value is the shorter\n                                text.\n-on, --on TEXT                  Column(s) to be mapped.\n-sc, --samecolor                Use the same color for same edges.\n-oroot, --outputroot TEXT       Path of the directory to store the graph\n                                (default: current directory). If the given\n                                path (i.e., --outputfile) is a relative\n                                path, it will be ignored.\n-ofile, --outputfile TEXT       Path of the file without extension to store\n                                the graph (default: res)\n-oformat, --outputformat [none|svg|png|gv]\n                                Format of the graph (default: none): none or\n                                svg or png or gv\n--help                          Show this message and exit.\n</code></pre> Example: visualize the <code>test</code> dataset <pre><code>geist graph rdflib --dataset test --outputformat svg \n</code></pre> <p>graph function can visualize a dataset. Only <code>rdflib</code> is supported for now.</p> <p>Parameters description for export():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: rdflib Key Type Description Default rankdir string Direction of the graph: TB or BT or LR or RL 'TB' mappings string File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text None on string Column(s) to be mapped None samecolor bool True to use the same color for same edges, otherwise False True outputroot string Path of the directory to store the graph './' outputfile string Path of the file without extension to store the graph 'res' outputformats list Format of the graph: 'none' or 'svg' or 'png' or 'gv' ['none'] Example: visualize the <code>test</code> dataset <pre><code>import geist\n\n# Visualize the test dataset as a graph and save it as the res.svg file\ngeist.graph(datastore='rdflib', dataset='test', hasoutput=True, config={'outputformats': ['svg']})\n</code></pre> <p>graph method of the Connection class exports a dataset. Only <code>rdflib</code> is supported for now. It is very similar to the <code>graph()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for graph method of the Connection class:</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: rdflib Key Type Description Default rankdir string Direction of the graph: TB or BT or LR or RL 'TB' mappings string File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text None on string Column(s) to be mapped None samecolor bool True to use the same color for same edges, otherwise False True outputroot string Path of the directory to store the graph './' outputfile string Path of the file without extension to store the graph 'res' outputformats list Format of the graph: 'none' or 'svg' or 'png' or 'gv' ['none'] Example 1: visualize the <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre> Example 2: visualize the <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre>"},{"location":"features/load/","title":"Load","text":"<p>load feature can import data into an existing dataset on disk or in memory.</p> <p>You can write a Geist template with the load tag. You can also use CLI or Python API step by step as follows:</p> CLI: load commandPython API: load() functionPython API: load method of the Connection Class <p>load command can import data into an existing dataset.</p> <p>There are two subcommands for load: <pre><code>Usage: geist load [OPTIONS] COMMAND [ARGS]...\n\nImport data into a dataset\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  duckdb  Import data into a SQL dataset\n  rdflib  Import data into a RDF dataset\n</code></pre></p> geist load duckdb [OPTIONS] <pre><code>Usage: geist load duckdb [OPTIONS]\n\nImport data into a SQL dataset\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to load a file (default\n                                \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as a table\n                                [required]\n-iformat, --inputformat [csv|json]\n                                Format of the file to be loaded as a table\n                                (default csv)\n-t, --table TEXT                Name of the table to be created  [required]\n--help                          Show this message and exit.\n</code></pre> Example: load a file into the <code>test</code> dataset <pre><code>geist load duckdb --dataset test --inputfile test_add.csv --inputformat csv --table df\n</code></pre> geist load rdflib [OPTIONS] <p>Here are options of the load command: <pre><code>Usage: geist load rdflib [OPTIONS]\n\nImport data into a RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to load a file (default\n                                \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as triples\n                                [required]\n-iformat, --inputformat [xml|n3|turtle|nt|pretty-xml|trix|trig|nquads|json-ld|hext|csv]\n                                Format of the file to be loaded as triples\n                                (default json-ld)\n--colnames TEXT                 Column names of triples with the format of\n                                [[subject1, predicate1, object1], [subject2,\n                                predicate2, object2], ...] when the input\n                                format is csv\n--help                          Show this message and exit.\n</code></pre></p> Example: load a file into the <code>test</code> dataset <pre><code>geist load rdflib --dataset test --inputfile test_add.jsonld\n</code></pre> <p>load function can import data into an existing dataset.</p> <p>Parameters description for query():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] inputfile string File to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be loaded [required] Key Type Description Default inmemory bool True if the new dataset (after loading data) is stored in memory only, otherwise it is stored on disk False colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv Example: load a table into the <code>test</code> dataset <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The <code>csv_str</code> will be imported into the <code>df</code> table. Note that the order of table columns should be consistent with the imported data.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,1,1\n2,2,2\n3,3,3\n\"\"\"\n\n# Load csv_str to the df table of the test dataset\ngeist.load(datastore='duckdb', dataset='test', inputfile=csv_str, inputformat='csv', isinputpath=False, config={'table': 'df'})\n</code></pre> <p>load method of the Connection class imports data into an existing dataset on disk or in memory. It is very similar to the <code>load()</code> function. The only difference is that <code>datastore</code>, <code>dataset</code>, and <code>inmemory</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for load method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be loaded [required] Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv Example: load a table into the <code>test</code> dataset <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The <code>csv_str</code> will be imported into the <code>df</code> table. Note that the order of table columns should be consistent with the imported data.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,1,1\n2,2,2\n3,3,3\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Load csv_str to the df table of the test dataset\nconnection.load(inputfile=csv_str, inputformat='csv', isinputpath=False, config={'table': 'df'})\n</code></pre>"},{"location":"features/query/","title":"Query","text":"<p>query feature can perform a query on a dataset stored on disk or in memory.</p> <p>You can write a Geist template with the query tag. You can also use CLI or Python API step by step as follows:</p> CLI: query commandPython API: query() functionPython API: query method of the Connection Class <p>The create command has two subcommands, both of which create a new dataset on disk. The dataset name <code>:memory:</code> is a reserved value for datasets that exist only in memory and is not allowed in the CLI.</p> <pre><code>Usage: geist create [OPTIONS] COMMAND [ARGS]...\n\nCreate a new dataset\n\nOptions:\n--help  Show this message and exit.\n\nCommands:\nduckdb  Create a new SQL dataset using DuckDB\nrdflib  Create a new RDF dataset using RDFLib\n</code></pre> geist create duckdb [OPTIONS] <pre><code>Usage: geist create duckdb [OPTIONS]\n\nCreate a new SQL dataset using DuckDB\n\nOptions:\n-d, --dataset TEXT              Name of SQL dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as a Pandas\n                                DataFrame  [required]\n-iformat, --inputformat [csv|json]\n                                Format of the file to be loaded as a Pandas\n                                DataFrame (default csv)\n-t, --table TEXT                Name of the table to be created (default\n                                \"df\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> SQL dataset from stdin <pre><code>geist create duckdb --dataset test --inputformat csv --table df &lt;&lt; __END_INPUT__\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>geist create duckdb --dataset test --inputfile test.csv --inputformat csv --table df\n</code></pre></p> geist create rdflib [OPTIONS] <pre><code>Usage: geist create rdflib [OPTIONS]\n\nCreate a new RDF dataset\n\nOptions:\n-d, --dataset TEXT              Name of RDF dataset to create (default \"kb\")\n-ifile, --inputfile FILENAME    Path of the file to be loaded as triples\n                                [required]\n-iformat, --inputformat [xml|n3|turtle|nt|pretty-xml|trix|trig|nquads|json-ld|hext|csv]\n                                Format of the file to be loaded as triples\n                                (default json-ld)\n--colnames TEXT                 Column names of triples with the format of\n                                [[subject1, predicate1, object1], [subject2,\n                                predicate2, object2], ...] when the input\n                                format is csv\n--infer [none|rdfs|owl|rdfs_owl]\n                                Inference to perform on update [none, rdfs,\n                                owl, rdfs_owl] (default \"none\")\n--help                          Show this message and exit.\n</code></pre> Example 1: create a <code>test</code> RDF dataset from stdin <pre><code>geist create rdflib --dataset test --inputformat nt --infer none &lt;&lt; __END_INPUT__\n\n&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n\n__END_INPUT__\n</code></pre> Example 2: create a <code>test</code> dataset from a file <p>Here is the <code>test.nt</code> file:</p> <p><pre><code>&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n</code></pre> Code: <pre><code>geist create rdflib --dataset test --inputfile test.nt --inputformat nt --infer none\n</code></pre></p> <p>query function can perform a query on a dataset.</p> <p>Parameters description for query():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] inputfile string File containing the query [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] hasoutput bool True to store the query results as a CSV file or print them out [required] config dict A dictionary with configurations when <code>hasoutput=True</code> see below <p>Description for the config parameter:</p> Key Type Description Default outputroot string Path of the directory to store the query results './' outputfile string Path of the file to store the query results None Example 1: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a string) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results, and a <code>DuckPyConnection</code> object.</p> <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset='test', inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 2: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a file) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results, and a <code>DuckPyConnection</code> object.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset='test', inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> Example 3: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a string) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results, and the same <code>DuckPyConnection</code> object.</p> <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset=conn, inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 4: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a file) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results, and the same <code>DuckPyConnection</code> object.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset=conn, inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> <p>query method of the Connection class can query a dataset stored on disk or in memory. It is very similar to the <code>query()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialze the Connection* class.</p> <p>Parameters description for query method of the Connection class:</p> Name Type Description Default inputfile string File containing the query [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] hasoutput bool True to store the query results as a CSV file or print them out [required] config dict A dictionary with configurations when <code>hasoutput=True</code> see below <p>Description for the config parameter:</p> Key Type Description Default outputroot string Path of the directory to store the query results './' outputfile string Path of the file to store the query results None Example 1: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a string) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 2: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a file) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> Example 3: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a string) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 4: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a file) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p>"},{"location":"features/report/","title":"Report","text":"<p>report feature can expand a report using dataset(s). </p> <p>The report is a Geist template:</p>"},{"location":"features/report/#geist-templates","title":"Geist Templates","text":""},{"location":"features/report/#what-is-a-geist-template","title":"What is a Geist template?","text":"<p>A Geist template is a text file without a specific extension requirement although adding a <code>.geist</code> extension is recommended. It is an extension of a Jinja template, therefore it follows the default Jinja delimiters:</p> <ul> <li><code>{% ... %}</code> for Statements</li> <li><code>{{ ... }}</code> for Expressions to print to the template output</li> <li><code>{# ... #}</code> for Comments not included in the template output</li> </ul>"},{"location":"features/report/#how-to-write-a-geist-template","title":"How to write a Geist template?","text":"<p>A Geist template relies on tags and filters.</p>"},{"location":"features/report/#tags","title":"Tags","text":"<p>Tags are used within the statements, i.e., <code>{% ... %}</code>. There are two types of tags, <code>StandaloneTag</code> and <code>ContainerTag</code>. While the <code>StandaloneTag</code> does not require a closing tag, the <code>ContainerTag</code> does. Besides the Jinja predefined tags (e.g., <code>for</code>), Geist supports the following tags:</p> <p><code>StandaloneTag</code>:</p> <ul> <li>destroy</li> <li>graph</li> <li>graph2</li> <li>use</li> </ul> <p><code>ContainerTag</code>:</p> <ul> <li>create</li> <li>load</li> <li>query</li> <li>component</li> <li>map</li> <li>html</li> <li>img</li> <li>table</li> </ul> <p>Custom tags can be defined through files with the use tag.</p>"},{"location":"features/report/#filters","title":"Filters","text":"<p>Filters are used to modify variables. Each filter can only take one variable as input. Multiple filters can be applied to a single variable in sequence. For example, <code>{{ var|filter1|filter2|filter3 }}</code> denotes the variable <code>var</code> will be processed through <code>filter1</code> first, then <code>filter2</code>, and <code>filter3</code> at the end.</p> <p>Geist supports the following filters:</p> <ul> <li>head: extract the first 5 rows of a Pandas data frame</li> <li>csv2df: convert a CSV string to a Pandas data frame</li> <li>json2df: convert a JSON string to a Pandas data frame</li> <li>dict2df: convert a dictionary to a Pandas data frame</li> <li>json2dict: convert a JSON string to a dictionary</li> <li>df2json: convert a Pandas data frame to a JSON string</li> <li>df2htmltable: convert a Pandas data frame to an HTML table</li> <li>escape_quotes: escape both double and single quotation marks</li> <li>process_str_for_html: preprocess a string to be displayed within an HTML document, e.g., replace <code>&lt;</code> with <code>&amp;lt</code></li> </ul>"},{"location":"features/report/#how-to-execute-expand-a-geist-template","title":"How to execute (expand) a Geist template?","text":"CLIPython API <p>report command can expand a report (Geist template) using dataset(s).</p> <p>Here are options of the report command: <pre><code>Usage: geist report [OPTIONS]\n\nExpand a report using dataset(s)\n\nOptions:\n-ifile, --inputfile FILENAME   Path of the file containing the report\n                                template to expand  [required]\n-oroot, --outputroot TEXT      Path of the directory to store the expanded\n                                report (default: current directory)\n-so, --suppressoutput BOOLEAN  Suppress output or not (default: False)\n--help                         Show this message and exit.\n</code></pre></p> Example 1: expand a report from stdin <pre><code>geist report &lt;&lt; END_TEMPLATE\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\nEND_TEMPLATE\n</code></pre> Example 2: expand a report from a file <pre><code>geist report --inputfile report.geist\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p> <p>report function can expand a report (Geist template) using dataset(s).</p> <p>Parameters description for report():</p> Name Type Description Default inputfile string A report to be expanded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content <code>False</code> outputroot string Path of the directory to store the expanded report current directory, i.e., <code>./</code> suppressoutput bool True to suppress output <code>True</code> Example 1: expand a report from a string <pre><code>import geist\n\nreport = \"\"\"\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\n\"\"\"\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile=report)\n</code></pre> Example 2: expand a report from a file <pre><code>import geist\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile='report.geist', isinputpath=True)\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p>"},{"location":"geist-templates/introduction/","title":"Geist Templates","text":""},{"location":"geist-templates/introduction/#what-is-a-geist-template","title":"What is a Geist template?","text":"<p>A Geist template is a text file without a specific extension requirement although adding a <code>.geist</code> extension is recommended. It is an extension of a Jinja template, therefore it follows the default Jinja delimiters:</p> <ul> <li><code>{% ... %}</code> for Statements</li> <li><code>{{ ... }}</code> for Expressions to print to the template output</li> <li><code>{# ... #}</code> for Comments not included in the template output</li> </ul>"},{"location":"geist-templates/introduction/#how-to-write-a-geist-template","title":"How to write a Geist template?","text":"<p>A Geist template relies on tags and filters.</p>"},{"location":"geist-templates/introduction/#tags","title":"Tags","text":"<p>Tags are used within the statements, i.e., <code>{% ... %}</code>. There are two types of tags, <code>StandaloneTag</code> and <code>ContainerTag</code>. While the <code>StandaloneTag</code> does not require a closing tag, the <code>ContainerTag</code> does. Besides the Jinja predefined tags (e.g., <code>for</code>), Geist supports the following tags:</p> <p><code>StandaloneTag</code>:</p> <ul> <li>destroy</li> <li>graph</li> <li>graph2</li> <li>use</li> </ul> <p><code>ContainerTag</code>:</p> <ul> <li>create</li> <li>load</li> <li>query</li> <li>component</li> <li>map</li> <li>html</li> <li>img</li> <li>table</li> </ul> <p>Custom tags can be defined through files with the use tag.</p>"},{"location":"geist-templates/introduction/#filters","title":"Filters","text":"<p>Filters are used to modify variables. Each filter can only take one variable as input. Multiple filters can be applied to a single variable in sequence. For example, <code>{{ var|filter1|filter2|filter3 }}</code> denotes the variable <code>var</code> will be processed through <code>filter1</code> first, then <code>filter2</code>, and <code>filter3</code> at the end.</p> <p>Geist supports the following filters:</p> <ul> <li>head: extract the first 5 rows of a Pandas data frame</li> <li>csv2df: convert a CSV string to a Pandas data frame</li> <li>json2df: convert a JSON string to a Pandas data frame</li> <li>dict2df: convert a dictionary to a Pandas data frame</li> <li>json2dict: convert a JSON string to a dictionary</li> <li>df2json: convert a Pandas data frame to a JSON string</li> <li>df2htmltable: convert a Pandas data frame to an HTML table</li> <li>escape_quotes: escape both double and single quotation marks</li> <li>process_str_for_html: preprocess a string to be displayed within an HTML document, e.g., replace <code>&lt;</code> with <code>&amp;lt</code></li> </ul>"},{"location":"geist-templates/introduction/#how-to-execute-expand-a-geist-template","title":"How to execute (expand) a Geist template?","text":"CLIPython API <p>report command can expand a report (Geist template) using dataset(s).</p> <p>Here are options of the report command: <pre><code>Usage: geist report [OPTIONS]\n\nExpand a report using dataset(s)\n\nOptions:\n-ifile, --inputfile FILENAME   Path of the file containing the report\n                                template to expand  [required]\n-oroot, --outputroot TEXT      Path of the directory to store the expanded\n                                report (default: current directory)\n-so, --suppressoutput BOOLEAN  Suppress output or not (default: False)\n--help                         Show this message and exit.\n</code></pre></p> Example 1: expand a report from stdin <pre><code>geist report &lt;&lt; END_TEMPLATE\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\nEND_TEMPLATE\n</code></pre> Example 2: expand a report from a file <pre><code>geist report --inputfile report.geist\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p> <p>report function can expand a report (Geist template) using dataset(s).</p> <p>Parameters description for report():</p> Name Type Description Default inputfile string A report to be expanded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content <code>False</code> outputroot string Path of the directory to store the expanded report current directory, i.e., <code>./</code> suppressoutput bool True to suppress output <code>True</code> Example 1: expand a report from a string <pre><code>import geist\n\nreport = \"\"\"\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\n\"\"\"\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile=report)\n</code></pre> Example 2: expand a report from a file <pre><code>import geist\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile='report.geist', isinputpath=True)\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p>"},{"location":"geist-templates/tags/tag-component/","title":"Tag component","text":"<p>The <code>component</code> tag finds connected components in a graph. It will return a dict where the key is the index of a component (e.g., 0, 1, 2, ...) and the value is a connected component. By default, the given string is a file path. However, it can be updated by setting the <code>isfilepath</code> field to False. Here are parameters of the <code>component</code> tag:</p> Name Description <code>isfilepath</code> A bool value to denote if the given data is a file path or not (by default: True, which denotes the given data is a file path) <code>edges</code> A list of list. [[start_node1, end_node1], [start_node2, end_node2], ...] or [[start_node1, end_node1, label1], [start_node2, end_node2, label2], ...] where these items are column names"},{"location":"geist-templates/tags/tag-create/","title":"Tag create","text":"<p>The <code>create</code> tag creates a dataset based on the given string. By default, the given string is a file path. However, it can be updated by setting the <code>isfilepath</code> field to False. Here are parameters of the <code>create</code> tag:</p> Name Description <code>dataset</code> Name of RDF dataset to create (by default, \"kb\") <code>datastore</code> Data backend. <code>duckdb</code> and <code>rdflib</code> are available for now. (by default, \"rdflib\") <code>inputformat</code> Format of the file to be loaded as triples (by default, \"json-ld\"). It has to be one of {\"xml\", \"n3\", \"turtle\", \"nt\", \"pretty-xml\", \"trix\", \"trig\", \"nquads\", \"json-ld\", \"hext\", \"csv\"} <code>infer</code> Inference to perform on update choosing from {\"none\", \"rdfs\", \"owl\", \"rdfs_owl\"} (by default, \"none\"). Please check OWL-RL document for detailed information. <code>isfilepath</code> A bool value to denote if the given data is a file path or not (by default: True, which denotes the given data is a file path) <code>table</code> Table name. Available for <code>duckdb</code> data backend only. <code>colnames</code> Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] when the input format is csv (by default, None). Available for <code>rdflib</code> data backend only. Example 1: the given string is not a file path <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n</code></pre> Example 2: the given string is a file path <p>Here is the <code>test.nt</code> file:</p> <pre><code>&lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n&lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n</code></pre> <p>Code: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=True %} test.nt {% endcreate %}\n</code></pre></p>"},{"location":"geist-templates/tags/tag-destroy/","title":"Tag destroy","text":"<p>The <code>destroy</code> tag deletes a dataset. Here are parameters of the <code>destroy</code> tag:</p> Name Description <code>dataset</code> Name of RDF dataset to be removed (default \"kb\") <code>datastore</code> Data backend. <code>duckdb</code> and <code>rdflib</code> are available for now. (by default, \"rdflib\") <code>quiet</code> Suppress error messages if the provided dataset does not exist Example: delete the <code>test</code> dataset <p><pre><code>{% destroy dataset=\"test\" %}\n</code></pre> OR <pre><code>{% destroy \"test\" %}\n</code></pre></p> <p>The <code>.geistdata/test.pkl</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can add the <code>quiet</code> parameter:</p> <pre><code>{% destroy \"test\", quiet=True %}\n</code></pre>"},{"location":"geist-templates/tags/tag-graph/","title":"Tag graph","text":"<p>The <code>graph</code> tag visualizes a dataset. Here are parameters of the <code>graph</code> tag:</p> Name Description <code>dataset</code> Name of RDF dataset to be visualized (default \"kb\") <code>datastore</code> Data backend. <code>duckdb</code> and <code>rdflib</code> are available for now. (by default, \"rdflib\") <code>rankdir</code> Direction of the graph (default TB): TB or BT or LR or RL <code>mappings</code> File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text. <code>on</code> Column(s) to be mapped (default None, which means all columns will be mapped) <code>samecolor</code> A bool value to denote if all edges are filled with the same color (default: True) Example: visualize the <code>test</code> dataset <pre><code>{% graph \"test\", datastore=\"rdflib\" %}\n</code></pre>"},{"location":"geist-templates/tags/tag-graph2/","title":"Tag graph2","text":"<p>The <code>graph2</code> tag visualizes a dataset. It does not rely on the <code>PyGraphviz</code> pacakge, which makes it more flexible compared to the <code>graph</code> tag. Here are parameters of the <code>graph2</code> tag:</p> Name Description <code>dataset</code> Name of RDF dataset to be visualized (default \"kb\") <code>rankdir</code> Direction of the graph (default TB): TB or BT or LR or RL <code>mappings</code> File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text. <code>on</code> Column(s) to be mapped (default None, which means all columns will be mapped) ... Graph attributes of Graphviz Example: visualize the <code>test</code> dataset <pre><code>{% graph2 dataset=\"test\" %}\n</code></pre>"},{"location":"geist-templates/tags/tag-html/","title":"Tag html","text":"<p>The <code>html</code> tag formats and saves the string as a HTML file. Here is a parameter of the <code>html</code> tag:</p> Name Description <code>path</code> Path of the HTML file to be saved. By default, <code>report.html</code> Save the 'Hello World!' string as a file <pre><code>{% html %}Hello World!{% endhtml %}\n</code></pre> <p>Expected content of the <code>report.html</code> file:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\nHello World!\n&lt;/html&gt;\n</code></pre>"},{"location":"geist-templates/tags/tag-img/","title":"Tag img","text":"<p>The <code>img</code> tag renders Graphviz code as an image and embeds it into HTML. Here are parameters of the <code>img</code> tag:</p> Name Description <code>src</code> Path of the rendered image to be saved. Various extensions are supported. Check PyGraphviz Docs for the whole list. Note: <code>dot</code> or <code>gv</code> will show code directly. ... Attributes of the HTML  or the HTML <code> tag Example 1: render as svg <pre><code>{% img src=\"test.svg\" %}digraph test_graph { node1 -&gt; node2 }{% endimg %}\n</code></pre> <p>A file named <code>test.svg</code> will be created and the Geist template will be updated as: <pre><code>&lt;img src=\"test.svg\" width=\"100%\" &gt;\n</code></pre></p> Example 2: render as gv <pre><code>{% img src=\"test.gv\" %}digraph test_graph { node1 -&gt; node2 }{% endimg %}\n</code></pre> <p>A file named <code>test.gv</code> will be created and the Geist template will be updated as: <pre><code>&lt;pre&gt;&lt;code&gt;digraph test_graph { node1 -&gt; node2 }&lt;/code&gt;&lt;/pre&gt;\n</code></pre></p>"},{"location":"geist-templates/tags/tag-load/","title":"Tag load","text":"<p>The <code>load</code> tag imports data into a dataset. Here are parameters of the <code>load</code> tag:</p> Name Description <code>dataset</code> Name of RDF dataset to be removed (default \"kb\") <code>datastore</code> Data backend. <code>duckdb</code> and <code>rdflib</code> are available for now. (by default, \"rdflib\") <code>inputformat</code> Format of the file to be loaded as triples (default json-ld) <code>isfilepath</code> A bool value to denote if the given data is a file path or not (default True, which denotes the given data is a file path) <code>table</code> Table name to be loaded. Available for <code>duckdb</code> data backend only. <code>colnames</code> Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] when the input format is csv. Available for <code>rdflib</code> data backend only. Example: load a file into the <code>test</code> dataset <pre><code>{% load \"test\", datastore=\"rdflib\" %} test_add.jsonld {% endload %}\n</code></pre>"},{"location":"geist-templates/tags/tag-map/","title":"Tag map","text":"<p>The <code>map</code> replaces the original string (JSON string) on selected columns (if provides) with the shorter ones based on the given mappings. By default, the given string is a file path. However, it can be updated by setting the <code>isfilepath</code> field to False. A Pandas DataFrame will be returned. Here are parameters of the <code>map</code> tag:</p> Name Description <code>isfilepath</code> A bool value to denote if the given data is a file path or not (by default: True, which denotes the given data is a file path) <code>mappings</code> File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text. <code>on</code> A column or a list of selected columns. All columns will be selected by default (None) data.json <pre><code>{\n    \"v1\": {\"0\":\"test_a1\",\"1\":\"test_b1\",\"2\":\"test_c1\"}, \n    \"v2\": {\"0\":\"test_a2\",\"1\":\"test_b2\",\"2\":\"test_c2\"},\n    \"v3\": {\"0\":\"test_a3\",\"1\":\"test_b3\",\"3\":\"test_c3\"}\n}\n</code></pre> mapping.json <pre><code>{\"test_\": \"\"}\n</code></pre> Example 1: replace all columns <pre><code>{%- map mappings=\"mappings.json\" as res %} data.json {% endmap %}\n{{ res }}\n</code></pre> <p>Expected output: <pre><code>v1,v2,v3\na1,a2,a3\nb1,b2,b3\nc1,c2,c3\n</code></pre></p> Example 2: replace selected columns <pre><code>{% map mappings=\"mappings.json\", on=[\"v1\",\"v2\"] as res %} data.json {% endmap %}\n{{ res }}\n</code></pre> <p>Expected output: <pre><code>v1,v2,v3\na1,a2,test_a3\nb1,b2,test_b3\nc1,c2,test_c3\n</code></pre></p> <p>If only \"v1\" column need to be replaced, you can replace <code>on=[\"v1\",\"v2\"]</code> with <code>on=\"v1\"</code>.</p>"},{"location":"geist-templates/tags/tag-query/","title":"Tag query","text":"<p>The <code>query</code> tag performs a query on a dataset and returns a Pandas DataFrame. Here are parameters of the <code>query</code> tag:</p> Name Description <code>dataset</code> Name of a dataset to query (default \"kb\") <code>datastore</code> Data backend. <code>duckdb</code> and <code>rdflib</code> are available for now. (by default, \"rdflib\") <code>isfilepath</code> A bool value to denote if the given data is a file path or not (default True, which denotes the given data is a file path) Example 1: the given string is not a file path <pre><code>{% query \"test\", datastore=\"rdflib\", isfilepath=False %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n</code></pre> Example 2: the given string is a file path <p><pre><code>{% query \"test\", datastore=\"rdflib\", isfilepath=True %} query_file {% endquery %}\n</code></pre> Here is the query_file's content: <pre><code>SELECT ?s ?p ?o\nWHERE {\n    ?s ?p ?o\n}\nORDER BY ?s ?p ?o\n</code></pre></p>"},{"location":"geist-templates/tags/tag-table/","title":"Tag table","text":"<p>The <code>table</code> tag embeds query results to HTML as a table. Please make sure the stdin is a JSON string. Here are parameters of the <code>table</code> tag:</p> Name Description <code>mappings</code> File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text. <code>on</code> A column or a list of selected columns. All columns will be selected by default (None) Example: embed query results as a table <pre><code>{% table %}\n    {%- query isfilepath=False as query_results %}\n        SELECT ?s ?p ?o\n        WHERE {\n            ?s ?p ?o\n        }\n        ORDER BY ?s ?p ?o\n    {% endquery %}\n    {{ query_results | df2json }}\n{% endtable %}\n</code></pre> <p>It can also be done with the df2htmltable filter: <pre><code>{%- query isfilepath=False as query_results %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n{{ query_results | df2htmltable }}\n</code></pre></p>"},{"location":"geist-templates/tags/tag-use/","title":"Tag use","text":"<p>The <code>use</code> tag can be used to define custom tags. Here is a parameter of the <code>use</code> tag:</p> Name Description <code>filepath</code> Path of a file to define custom tags <p>Here is the structure of tags to be defined within the file at the path <code>filepath</code>: <pre><code>{% template TAG_NAME PARAM1 PARAM2 %}\n    CONTENT\n{% endtemplate %}\n</code></pre> You need to update <code>TAG_NAME</code>, <code>PARAM1</code>, <code>PARAM2</code>, and <code>CONTENT</code> based on your use case. <code>TAG_NAME</code> must be unique, which means you cannot define multiple tags with the same name. You can have any number of parameters, which means <code>{% template TAG_NAME %}</code> and <code>{% template TAG_NAME PARAM1 PARAM2 PARAM3 %}</code> are also valid. Nested tags are also supported, which means you can put another tag within the <code>CONTENT</code> part.</p> Example: define <code>predicate_term</code> and <code>format_output</code> tags <ol> <li> <p>Write <code>{% use \"templates.geist\" %}</code> at the beginning of a Geist template, where you want to use the custom tags, i.e., <code>predicate_term</code> and <code>format_output</code> tags.</p> </li> <li> <p>Define custom tags in file with the path of \"templates.geist\":</p> <pre><code>{% template predicate_term %}says{% endtemplate %}\n\n{% template format_output person sent %}\n    {{ person }} {% predicate_term %} {{sent}}\n{% endtemplate %}\n</code></pre> </li> <li> <p>Use custom tags in the Geist template as other predefined tags (e.g., create)</p> <pre><code>{% use \"templates.geist\" %}\n\n{%- create inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/test1&gt; &lt;http://example.com/p1&gt; \"Hello World\".\n    &lt;http://example.com/test2&gt; &lt;http://example.com/p2&gt; \"What a Nice Day\".\n{% endcreate %}\n\n{%- query \"kb1\", isfilepath=False as res %}\n    SELECT ?s ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?o\n{% endquery %}\n{% set all_triples = res | json2df %}\n\n{% for _, row in all_triples.iterrows() %}\n    {% format_output row[\"s\"], row[\"o\"] %}.\n{%- endfor %}\n\n{%- destroy %}\n</code></pre> </li> <li> <p>Expected output:</p> <pre><code>&lt;http://example.com/test1&gt; says Hello World.\n&lt;http://example.com/test2&gt; says What a Nice Day.\n</code></pre> </li> </ol>"},{"location":"python-api/create/","title":"Function create","text":"<p>create function can create a new dataset on disk or in memory.</p> <p>Parameters description for create():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset to be created. Note that <code>:memory:</code> is a reserved value for datasets that exist only in memory [required] inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset on disk from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset on disk from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p>"},{"location":"python-api/destroy/","title":"Function destroy","text":"<p>destroy function can delete a dataset.</p> <p>Parameters description for destroy():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset to be removed. [required] quiet bool True to suppress error messages if the provided dataset does not exist False Example: delete the <code>test</code> dataset <pre><code>import geist\ngeist.destroy(datastore='rdflib', dataset='test')\n</code></pre> <p>The <code>.geistdata/rdflib/test.pkl</code> file will be removed after this operation. By default, you will get an error message if the provided dataset (in this case, it is the <code>test</code> dataset) does not exist. To suppress this error message, you can set <code>quiet=True</code>:</p> <pre><code>import geist\ngeist.destroy(datastore='rdflib', dataset='test', quiet=True)\n</code></pre>"},{"location":"python-api/export/","title":"Function export","text":"<p>export function can export a dataset.</p> <p>Parameters description for export():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default outputroot string Path of the directory to store the exported table './' outputfile string Path of the file to store the exported table None outputformat string Format of the exported table, i.e., 'csv' or 'json' 'csv' table string Name of the table to be exported 'df' Key Type Description Default outputroot string Path of the directory to store these exported triples './' outputfile string Path of the file to store these exported triples None outputformat string Format of the exported triples, i.e., 'json-ld', 'n3', 'nquads', 'nt', 'hext', 'pretty-xml', 'trig', 'trix', 'turtle', 'longturtle', or 'xml'. 'nt' Example 1: export all rows of the <code>df</code> table in <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>data</code> and the DuckPyConnection<code>object</code>conn`.</p> <pre><code>import geist\n\n# Export the df table of the test dataset\n(data, conn) = geist.export(datastore='duckdb', dataset='test', hasoutput=False, config={'table': 'df'})\n</code></pre> Example 2: export all rows of the <code>df</code> table in <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>data</code> and the same DuckPyConnection<code>object</code>conn`.</p> <pre><code>import geist\n\n# Export the df table of the test dataset\n(data, conn) = geist.export(datastore='duckdb', dataset=conn, hasoutput=False, config={'table': 'df'})\n</code></pre>"},{"location":"python-api/graph/","title":"Function graph","text":"<p>graph function can visualize a dataset. Only <code>rdflib</code> is supported for now.</p> <p>Parameters description for export():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: rdflib Key Type Description Default rankdir string Direction of the graph: TB or BT or LR or RL 'TB' mappings string File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text None on string Column(s) to be mapped None samecolor bool True to use the same color for same edges, otherwise False True outputroot string Path of the directory to store the graph './' outputfile string Path of the file without extension to store the graph 'res' outputformats list Format of the graph: 'none' or 'svg' or 'png' or 'gv' ['none'] Example: visualize the <code>test</code> dataset <pre><code>import geist\n\n# Visualize the test dataset as a graph and save it as the res.svg file\ngeist.graph(datastore='rdflib', dataset='test', hasoutput=True, config={'outputformats': ['svg']})\n</code></pre>"},{"location":"python-api/load/","title":"Function load","text":"<p>load function can import data into an existing dataset.</p> <p>Parameters description for query():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] inputfile string File to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be loaded [required] Key Type Description Default inmemory bool True if the new dataset (after loading data) is stored in memory only, otherwise it is stored on disk False colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv Example: load a table into the <code>test</code> dataset <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The <code>csv_str</code> will be imported into the <code>df</code> table. Note that the order of table columns should be consistent with the imported data.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,1,1\n2,2,2\n3,3,3\n\"\"\"\n\n# Load csv_str to the df table of the test dataset\ngeist.load(datastore='duckdb', dataset='test', inputfile=csv_str, inputformat='csv', isinputpath=False, config={'table': 'df'})\n</code></pre>"},{"location":"python-api/query/","title":"Function query","text":"<p>query function can perform a query on a dataset.</p> <p>Parameters description for query():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR DuckPyConnection object OR GeistGraph object (1) A string indicates the name of the dataset stored on disk OR (2) a DuckPyConnection object OR a GeistGraph object for dataset in memory [required] inputfile string File containing the query [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] hasoutput bool True to store the query results as a CSV file or print them out [required] config dict A dictionary with configurations when <code>hasoutput=True</code> see below <p>Description for the config parameter:</p> Key Type Description Default outputroot string Path of the directory to store the query results './' outputfile string Path of the file to store the query results None Example 1: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a string) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results, and a <code>DuckPyConnection</code> object.</p> <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset='test', inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 2: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a file) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results, and a <code>DuckPyConnection</code> object.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset='test', inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> Example 3: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a string) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results, and the same <code>DuckPyConnection</code> object.</p> <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset=conn, inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 4: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a file) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results, and the same <code>DuckPyConnection</code> object.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Query the df table of the test dataset\n(res, conn) = geist.query(datastore='duckdb', dataset=conn, inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p>"},{"location":"python-api/report/","title":"Function report","text":"<p>report function can expand a report (Geist template) using dataset(s).</p> <p>Parameters description for report():</p> Name Type Description Default inputfile string A report to be expanded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content <code>False</code> outputroot string Path of the directory to store the expanded report current directory, i.e., <code>./</code> suppressoutput bool True to suppress output <code>True</code> Example 1: expand a report from a string <pre><code>import geist\n\nreport = \"\"\"\n\n{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n\n\"\"\"\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile=report)\n</code></pre> Example 2: expand a report from a file <pre><code>import geist\n\n# Return the expanded report as a string variable named expanded_report\nexpanded_report = geist.report(inputfile='report.geist', isinputpath=True)\n</code></pre> <p>Here is the report.geist file: <pre><code>{% create \"test\", datastore=\"rdflib\", inputformat=\"nt\", isfilepath=False %}\n    &lt;http://example.com/drewp&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\n    &lt;http://example.com/drewp&gt; &lt;http://example.com/says&gt; \"Hello World\" .\n{% endcreate %}\n\n{% query \"test\", datastore=\"rdflib\", isfilepath=False as all_triples %}\n    SELECT ?s ?p ?o\n    WHERE {\n        ?s ?p ?o\n    }\n    ORDER BY ?s ?p ?o\n{% endquery %}\n\n{% for _, row in all_triples.iterrows() %}\n    Subject: {{ row[\"s\"] }}, Predicate: {{ row[\"p\"] }}, Object: {{ row[\"o\"] }}.\n{% endfor %}\n\n{% destroy \"test\", datastore=\"rdflib\" %}\n</code></pre></p>"},{"location":"python-api/connect/Connection/","title":"Class Connection","text":"<p>Connection class can interact with a dataset with create, close, destroy, export, graph, load, and query methods.</p>"},{"location":"python-api/connect/Connection/#what-is-a-connection-class","title":"What is a Connection class?","text":"<p>A Connection class has three attributes:</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset. Note that <code>:memory:</code> is a reserved value for datasets that exist only in memory [required] conn object Name of the table to be created None"},{"location":"python-api/connect/Connection/#how-to-instantiate-a-connection-class","title":"How to instantiate a Connection class?","text":"<p>If the dataset exists, the Connection class can be instantiated using its connect method:</p> <pre><code># create a Connection object to an existing dataset named test\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n</code></pre> <p>If the dataset does not exist, there are two approaches to create and connect:</p> Approach 1: use the create() function, then initialize the Connection class create() function <p>create function can create a new dataset on disk or in memory.</p> <p>Parameters description for create():</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string Name of the dataset to be created. Note that <code>:memory:</code> is a reserved value for datasets that exist only in memory [required] inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset on disk from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset on disk from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset='test', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>DuckDBPyConnection</code> object is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>DuckDBPyConnection</code> object is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a DuckPyConnection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n7,8,9\n\"\"\"\n\n# create a Connection object\nconn = geist.create(datastore='duckdb', dataset=':memory:', inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n</code></pre> Approach 2: use the connect method of the Connection class create method of the Connection class <p>create method of the Connection class creates a new dataset on disk or in memory. It is very similar to the <code>create()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for create method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n7,8,9\n\"\"\"\n\n# create a Connection object\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre>"},{"location":"python-api/connect/Connection/#how-to-interact-with-a-connection-class","title":"How to interact with a Connection class?","text":"<p>Once a Connection class is instantiated, we can interact with it using close, destroy, export, graph, load, and query methods.</p> close method <p>close method of the Connection* class is to close the dataset connection, i.e., reset all attributes to None. No parameters are required.</p> Example: close the connection <p>Suppose <code>connection</code> is the instance of the Connection class.</p> <pre><code># Close the connection\nconnection.close()\n</code></pre> destroy method <p>destroy method of the Connection* class is to delete the dataset and close the dataset connection.</p> Example: delete the dataset and close the connection <p>Suppose <code>connection</code> is the instance of the Connection class for a DuckDB dataset named <code>test</code> stored on disk. The following code will delete the <code>.geistdata/duckdb/test.duckdb</code> file.</p> <pre><code># Delete the dataset and close the connection\nconnection.destroy()\n</code></pre> export method <p>export method of the Connection class exports a dataset. It is very similar to the <code>export()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for export method of the Connection class:</p> Name Type Description Default hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default outputroot string Path of the directory to store the exported table './' outputfile string Path of the file to store the exported table None outputformat string Format of the exported table, i.e., 'csv' or 'json' 'csv' table string Name of the table to be exported 'df' Key Type Description Default outputroot string Path of the directory to store these exported triples './' outputfile string Path of the file to store these exported triples None outputformat string Format of the exported triples, i.e., 'json-ld', 'n3', 'nquads', 'nt', 'hext', 'pretty-xml', 'trig', 'trix', 'turtle', 'longturtle', or 'xml'. 'nt' Example 1: export all rows of the <code>df</code> table in <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Export the df table of the test dataset\ndata = connection.export(hasoutput=False, config={'table': 'df'})\n</code></pre> Example 2: export all rows of the <code>df</code> table in <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Export the df table of the test dataset\ndata = connection.export( hasoutput=False, config={'table': 'df'})\n</code></pre> graph method <p>graph method of the Connection class exports a dataset. Only <code>rdflib</code> is supported for now. It is very similar to the <code>graph()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for graph method of the Connection class:</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: rdflib Key Type Description Default rankdir string Direction of the graph: TB or BT or LR or RL 'TB' mappings string File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text None on string Column(s) to be mapped None samecolor bool True to use the same color for same edges, otherwise False True outputroot string Path of the directory to store the graph './' outputfile string Path of the file without extension to store the graph 'res' outputformats list Format of the graph: 'none' or 'svg' or 'png' or 'gv' ['none'] Example 1: visualize the <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre> Example 2: visualize the <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre> load method <p>load method of the Connection class imports data into an existing dataset on disk or in memory. It is very similar to the <code>load()</code> function. The only difference is that <code>datastore</code>, <code>dataset</code>, and <code>inmemory</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for load method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be loaded [required] Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv Example: load a table into the <code>test</code> dataset <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The <code>csv_str</code> will be imported into the <code>df</code> table. Note that the order of table columns should be consistent with the imported data.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,1,1\n2,2,2\n3,3,3\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Load csv_str to the df table of the test dataset\nconnection.load(inputfile=csv_str, inputformat='csv', isinputpath=False, config={'table': 'df'})\n</code></pre> query method <p>query method of the Connection class can query a dataset stored on disk or in memory. It is very similar to the <code>query()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialze the Connection* class.</p> <p>Parameters description for query method of the Connection class:</p> Name Type Description Default inputfile string File containing the query [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] hasoutput bool True to store the query results as a CSV file or print them out [required] config dict A dictionary with configurations when <code>hasoutput=True</code> see below <p>Description for the config parameter:</p> Key Type Description Default outputroot string Path of the directory to store the query results './' outputfile string Path of the file to store the query results None Example 1: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a string) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 2: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a file) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> Example 3: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a string) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 4: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a file) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p>"},{"location":"python-api/connect/close/","title":"Close","text":"<p>close method of the Connection* class is to close the dataset connection, i.e., reset all attributes to None. No parameters are required.</p> Example: close the connection <p>Suppose <code>connection</code> is the instance of the Connection class.</p> <pre><code># Close the connection\nconnection.close()\n</code></pre>"},{"location":"python-api/connect/create/","title":"Create","text":"<p>create method of the Connection class creates a new dataset on disk or in memory. It is very similar to the <code>create()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for create method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be created df Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv infer string Inference to perform on update, i.e., none, rdfs, owl, or rdfs_owl none Example 1: create a <code>test</code> SQL dataset from a string <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 2: create a <code>test</code> SQL dataset from a file <p>The <code>.geistdata/duckdb/test.duckdb</code> file is created and a <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset='test')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p> Example 3: create a SQL dataset in memory from a string <p>A <code>Connection</code> instance is returned.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=csv_str, inputformat=\"csv\", isinputpath=False, config={\"table\": \"df\"})\n</code></pre> Example 4: create a SQL dataset in memory from a file <p>A <code>Connection</code> instance is returned.</p> <p>Here is the <code>test.csv</code> file:</p> <pre><code>v1,v2,v3\n1,2,3\n4,5,6\n7,8,9\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:')\nconnection.create(inputfile=\"test.csv\", inputformat=\"csv\", isinputpath=True, config={\"table\": \"df\"})\n</code></pre></p>"},{"location":"python-api/connect/destroy/","title":"Destroy","text":"<p>destroy method of the Connection* class is to delete the dataset and close the dataset connection.</p> Example: delete the dataset and close the connection <p>Suppose <code>connection</code> is the instance of the Connection class for a DuckDB dataset named <code>test</code> stored on disk. The following code will delete the <code>.geistdata/duckdb/test.duckdb</code> file.</p> <pre><code># Delete the dataset and close the connection\nconnection.destroy()\n</code></pre>"},{"location":"python-api/connect/export/","title":"Export","text":"<p>export method of the Connection class exports a dataset. It is very similar to the <code>export()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for export method of the Connection class:</p> Name Type Description Default hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default outputroot string Path of the directory to store the exported table './' outputfile string Path of the file to store the exported table None outputformat string Format of the exported table, i.e., 'csv' or 'json' 'csv' table string Name of the table to be exported 'df' Key Type Description Default outputroot string Path of the directory to store these exported triples './' outputfile string Path of the file to store these exported triples None outputformat string Format of the exported triples, i.e., 'json-ld', 'n3', 'nquads', 'nt', 'hext', 'pretty-xml', 'trig', 'trix', 'turtle', 'longturtle', or 'xml'. 'nt' Example 1: export all rows of the <code>df</code> table in <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Export the df table of the test dataset\ndata = connection.export(hasoutput=False, config={'table': 'df'})\n</code></pre> Example 2: export all rows of the <code>df</code> table in <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>data</code>.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Export the df table of the test dataset\ndata = connection.export( hasoutput=False, config={'table': 'df'})\n</code></pre>"},{"location":"python-api/connect/graph/","title":"Graph","text":"<p>graph method of the Connection class exports a dataset. Only <code>rdflib</code> is supported for now. It is very similar to the <code>graph()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for graph method of the Connection class:</p> Name Type Description Default datastore string A backend datastore, i.e., rdflib or duckdb [required] dataset string OR GeistGraph object Dataset to load an object: (1) A string indicates the name of the dataset stored on disk OR (2) a GeistGraph object for dataset in memory [required] hasoutput bool True to export as a file or print it out [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: rdflib Key Type Description Default rankdir string Direction of the graph: TB or BT or LR or RL 'TB' mappings string File of the mappings to shorten text (str): path of a JSON file, where the key is the original text and the value is the shorter text None on string Column(s) to be mapped None samecolor bool True to use the same color for same edges, otherwise False True outputroot string Path of the directory to store the graph './' outputfile string Path of the file without extension to store the graph 'res' outputformats list Format of the graph: 'none' or 'svg' or 'png' or 'gv' ['none'] Example 1: visualize the <code>test</code> dataset on disk <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre> Example 2: visualize the <code>test</code> dataset in memory <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code visualizes the test dataset as a graph and saves it as the res.svg file.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Visualize the test dataset\nconnection.graph(hasoutput=True, config={'outputformats': ['svg']})\n</code></pre>"},{"location":"python-api/connect/load/","title":"Load","text":"<p>load method of the Connection class imports data into an existing dataset on disk or in memory. It is very similar to the <code>load()</code> function. The only difference is that <code>datastore</code>, <code>dataset</code>, and <code>inmemory</code> parameters do not need to be passed as they have already been specified while initialzing the Connection* class.</p> <p>Parameters description for load method of the Connection class:</p> Name Type Description Default inputfile string A file to be loaded [required] inputformat string Format of the file to be loaded [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] config dict A dictionary with configurations for certain backend store see below <p>Description for the config parameter:</p> datastore: duckdbdatastore: rdflib Key Type Description Default table string Name of the table to be loaded [required] Key Type Description Default colnames string Column names of triples with the format of [[subject1, predicate1, object1], [subject2, predicate2, object2], ...] [required] when inputformat=csv Example: load a table into the <code>test</code> dataset <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The <code>csv_str</code> will be imported into the <code>df</code> table. Note that the order of table columns should be consistent with the imported data.</p> <pre><code>import geist\n\ncsv_str = \"\"\"\nv1,v2,v3\n1,1,1\n2,2,2\n3,3,3\n\"\"\"\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Load csv_str to the df table of the test dataset\nconnection.load(inputfile=csv_str, inputformat='csv', isinputpath=False, config={'table': 'df'})\n</code></pre>"},{"location":"python-api/connect/query/","title":"Query","text":"<p>query method of the Connection class can query a dataset stored on disk or in memory. It is very similar to the <code>query()</code> function. The only difference is that the <code>datastore</code> and the <code>dataset</code> parameters do not need to be passed as they have already been specified while initialze the Connection* class.</p> <p>Parameters description for query method of the Connection class:</p> Name Type Description Default inputfile string File containing the query [required] isinputpath bool True if the inputfile is the file path, otherwise the inputfile is the content [required] hasoutput bool True to store the query results as a CSV file or print them out [required] config dict A dictionary with configurations when <code>hasoutput=True</code> see below <p>Description for the config parameter:</p> Key Type Description Default outputroot string Path of the directory to store the query results './' outputfile string Path of the file to store the query results None Example 1: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a string) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 2: all rows of the <code>df</code> table in <code>test</code> dataset on disk (query from a file) <p>There exist a file with the path of <code>.geistdata/duckdb/test.duckdb</code>. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection.connect(datastore='duckdb', dataset='test')\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p> Example 3: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a string) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"SELECT * FROM df;\", isinputpath=False, hasoutput=False)\n</code></pre> Example 4: all rows of the <code>df</code> table in <code>test</code> dataset in memory (query from a file) <p>Suppose <code>conn</code> is a <code>DuckPyConnection</code> object points to a DuckDB dataset in memory. The following code returns a Pandas data frame named <code>res</code> with query results.</p> <p>Here is the <code>query.txt</code> file:</p> <pre><code>SELECT * FROM df;\n</code></pre> <p>Code: <pre><code>import geist\n\n# Create a Connection instance\nconnection = geist.Connection(datastore='duckdb', dataset=':memory:', conn=conn)\n# Query the df table of the test dataset\nres = connection.query(inputfile=\"query.txt\", isinputpath=True, hasoutput=False)\n</code></pre></p>"}]}